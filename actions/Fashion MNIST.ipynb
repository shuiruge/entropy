{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "07274ccd-76f1-46a0-b64d-29dd3d7b8019",
   "metadata": {},
   "source": [
    "## Motivation\n",
    "\n",
    "In this notebook, we exame the idea declared in section 1.5.5 on Fashion MNIST data, a classification task.\n",
    "\n",
    "The model follows: https://www.kaggle.com/code/m0hand/fashion-mnist-cnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b8ab63f7-841b-4fe7-ae73-b0f8a207430e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-21 11:53:18.223829: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE3 SSE4.1 SSE4.2 AVX AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "from keras.models import Sequential\n",
    "from keras.losses import MSE, CategoricalCrossentropy\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tqdm import tqdm\n",
    "\n",
    "from utils import get_gradient_loss_fn\n",
    "\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c8239d4-600f-4b3d-b665-ba64d9bac711",
   "metadata": {},
   "source": [
    "## The MNIST Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d7ff4901-8ca8-4413-80ed-9184138a1ffa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([60000, 28, 28]), TensorShape([60000, 10]))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist = tf.keras.datasets.fashion_mnist\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "x_train = tf.convert_to_tensor(x_train / 255.0, 'float32')\n",
    "x_test = tf.convert_to_tensor(x_test / 255.0, 'float32')\n",
    "y_train = tf.one_hot(y_train, 10, dtype='float32')\n",
    "y_test = tf.one_hot(y_test, 10, dtype='float32')\n",
    "\n",
    "x_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "405d08b9-61df-44d1-a10f-9b2297783c3b",
   "metadata": {},
   "source": [
    "## Train a Model with Gradient Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "65e2d654-323d-43d2-805e-3a10fa1c28d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([ \n",
    "    Conv2D(64, (3, 3), activation='relu', input_shape=(28,28,1)),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    \n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "\n",
    "    Flatten(),\n",
    "    Dense(64, 'relu'),\n",
    "    Dense(10, 'softmax')\n",
    "])\n",
    "\n",
    "gradient_loss_fn = get_gradient_loss_fn(\n",
    "    lambda inputs: MSE(inputs[1], model(inputs[0]))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ac0e9b1c-d29b-4ef7-8ede-d29b98e069d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.optimizers.Adam()\n",
    "\n",
    "@tf.function\n",
    "def train_step(x, y):\n",
    "    with tf.GradientTape() as tape:\n",
    "        loss = gradient_loss_fn((x, y))\n",
    "    grads = tape.gradient(loss, model.variables)\n",
    "    optimizer.apply_gradients(zip(grads, model.variables))\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bd90d270-d554-4474-b95b-33c6826fee95",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model):\n",
    "    return accuracy_score(\n",
    "        tf.argmax(y_test, axis=1),\n",
    "        tf.argmax(model(x_test), axis=1),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1992d379-bf40-4022-bcd6-6d26c2b757f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
    "ds = ds.batch(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7f8317b9-e6c9-4c30-b3c6-7036e6785d07",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████| 600/600 [00:57<00:00, 10.42it/s]\n",
      "2024-03-21 11:54:18.114825: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 1730560000 exceeds 10% of free system memory.\n",
      "2024-03-21 11:54:18.580471: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 1730560000 exceeds 10% of free system memory.\n",
      "2024-03-21 11:54:19.019070: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 1730560000 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.0007949429 0.8572\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████| 600/600 [00:59<00:00, 10.05it/s]\n",
      "2024-03-21 11:55:20.010328: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 1730560000 exceeds 10% of free system memory.\n",
      "2024-03-21 11:55:20.529951: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 1730560000 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 0.00067475165 0.8771\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████| 600/600 [01:05<00:00,  9.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 0.0005717427 0.8892\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████| 600/600 [01:05<00:00,  9.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 0.00048587602 0.8928\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████| 600/600 [01:04<00:00,  9.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 0.00044733993 0.8953\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████| 600/600 [01:03<00:00,  9.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 0.00040259212 0.897\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████| 600/600 [01:01<00:00,  9.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 0.0003850808 0.8999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████| 600/600 [00:57<00:00, 10.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7 0.0004129472 0.9038\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████| 600/600 [00:57<00:00, 10.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 0.00047251425 0.9026\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████| 600/600 [00:57<00:00, 10.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9 0.00040916956 0.9006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████| 600/600 [00:58<00:00, 10.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 0.00038313595 0.901\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████| 600/600 [00:58<00:00, 10.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11 0.0004143991 0.9021\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████| 600/600 [00:58<00:00, 10.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12 0.0003378162 0.9061\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████| 600/600 [00:57<00:00, 10.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13 0.00037573426 0.902\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████| 600/600 [00:58<00:00, 10.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14 0.0003549408 0.9033\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████| 600/600 [00:57<00:00, 10.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15 0.00030916827 0.905\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████| 600/600 [00:58<00:00, 10.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16 0.0004225934 0.8983\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████| 600/600 [00:57<00:00, 10.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17 0.00047631082 0.8913\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████| 600/600 [00:56<00:00, 10.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18 0.00039022867 0.8891\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████| 600/600 [00:56<00:00, 10.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19 0.00033668807 0.8996\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(20):\n",
    "    for x, y in tqdm(ds):\n",
    "        loss = train_step(x, y)\n",
    "    print(epoch, loss.numpy(), evaluate(model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "55dde9a7-4018-4e64-b909-e069729f096c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8996"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7218605-525e-445c-aa7a-0e44d3d39dc1",
   "metadata": {},
   "source": [
    "## Baseline Model with Usual Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b9993ada-54dd-4b1f-ab9e-3e3301695c99",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_model = Sequential([ \n",
    "    Conv2D(64, (3, 3), activation='relu', input_shape=(28,28,1)),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    \n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "\n",
    "    Flatten(),\n",
    "    Dense(64, 'relu'),\n",
    "    Dense(10, 'softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2dc98178-5940-4567-be22-6735de610d85",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_model.compile(\n",
    "    optimizer='adam',\n",
    "    loss=CategoricalCrossentropy(),\n",
    "    # loss=MSE,\n",
    "    metrics=['accuracy'],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9fe0e479-a012-4538-a6ca-132352299fc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1875/1875 - 27s - loss: 0.4514 - accuracy: 0.8369 - val_loss: 0.3497 - val_accuracy: 0.8718 - 27s/epoch - 14ms/step\n",
      "Epoch 2/20\n",
      "1875/1875 - 26s - loss: 0.3023 - accuracy: 0.8900 - val_loss: 0.3574 - val_accuracy: 0.8675 - 26s/epoch - 14ms/step\n",
      "Epoch 3/20\n",
      "1875/1875 - 26s - loss: 0.2603 - accuracy: 0.9042 - val_loss: 0.2963 - val_accuracy: 0.8909 - 26s/epoch - 14ms/step\n",
      "Epoch 4/20\n",
      "1875/1875 - 26s - loss: 0.2294 - accuracy: 0.9149 - val_loss: 0.2675 - val_accuracy: 0.9024 - 26s/epoch - 14ms/step\n",
      "Epoch 5/20\n",
      "1875/1875 - 26s - loss: 0.2056 - accuracy: 0.9237 - val_loss: 0.2706 - val_accuracy: 0.9025 - 26s/epoch - 14ms/step\n",
      "Epoch 6/20\n",
      "1875/1875 - 26s - loss: 0.1843 - accuracy: 0.9313 - val_loss: 0.2874 - val_accuracy: 0.8994 - 26s/epoch - 14ms/step\n",
      "Epoch 7/20\n",
      "1875/1875 - 26s - loss: 0.1650 - accuracy: 0.9377 - val_loss: 0.2527 - val_accuracy: 0.9148 - 26s/epoch - 14ms/step\n",
      "Epoch 8/20\n",
      "1875/1875 - 26s - loss: 0.1485 - accuracy: 0.9441 - val_loss: 0.2687 - val_accuracy: 0.9102 - 26s/epoch - 14ms/step\n",
      "Epoch 9/20\n",
      "1875/1875 - 26s - loss: 0.1357 - accuracy: 0.9495 - val_loss: 0.2781 - val_accuracy: 0.9102 - 26s/epoch - 14ms/step\n",
      "Epoch 10/20\n",
      "1875/1875 - 26s - loss: 0.1230 - accuracy: 0.9543 - val_loss: 0.3104 - val_accuracy: 0.9014 - 26s/epoch - 14ms/step\n",
      "Epoch 11/20\n",
      "1875/1875 - 26s - loss: 0.1118 - accuracy: 0.9579 - val_loss: 0.2694 - val_accuracy: 0.9153 - 26s/epoch - 14ms/step\n",
      "Epoch 12/20\n",
      "1875/1875 - 26s - loss: 0.1009 - accuracy: 0.9622 - val_loss: 0.3122 - val_accuracy: 0.9107 - 26s/epoch - 14ms/step\n",
      "Epoch 13/20\n",
      "1875/1875 - 26s - loss: 0.0897 - accuracy: 0.9662 - val_loss: 0.3515 - val_accuracy: 0.9109 - 26s/epoch - 14ms/step\n",
      "Epoch 14/20\n",
      "1875/1875 - 26s - loss: 0.0839 - accuracy: 0.9678 - val_loss: 0.3368 - val_accuracy: 0.9129 - 26s/epoch - 14ms/step\n",
      "Epoch 15/20\n",
      "1875/1875 - 26s - loss: 0.0752 - accuracy: 0.9714 - val_loss: 0.3622 - val_accuracy: 0.9093 - 26s/epoch - 14ms/step\n",
      "Epoch 16/20\n",
      "1875/1875 - 26s - loss: 0.0733 - accuracy: 0.9728 - val_loss: 0.3659 - val_accuracy: 0.9121 - 26s/epoch - 14ms/step\n",
      "Epoch 17/20\n",
      "1875/1875 - 26s - loss: 0.0632 - accuracy: 0.9766 - val_loss: 0.4303 - val_accuracy: 0.9062 - 26s/epoch - 14ms/step\n",
      "Epoch 18/20\n",
      "1875/1875 - 26s - loss: 0.0606 - accuracy: 0.9774 - val_loss: 0.3946 - val_accuracy: 0.9131 - 26s/epoch - 14ms/step\n",
      "Epoch 19/20\n",
      "1875/1875 - 26s - loss: 0.0552 - accuracy: 0.9791 - val_loss: 0.4228 - val_accuracy: 0.9098 - 26s/epoch - 14ms/step\n",
      "Epoch 20/20\n",
      "1875/1875 - 26s - loss: 0.0511 - accuracy: 0.9802 - val_loss: 0.4548 - val_accuracy: 0.9097 - 26s/epoch - 14ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7f76ac141d10>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline_model.fit(\n",
    "    x_train, y_train,\n",
    "    epochs=20,\n",
    "    validation_data=(x_test, y_test),\n",
    "    verbose=2,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "637a961b-4f4b-4c9a-a5d3-b944c1ea01a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9097"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(baseline_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cff6385a-4ca4-45fb-bf99-9953641fec71",
   "metadata": {},
   "source": [
    "## Model Robustness\n",
    "\n",
    "Now, we compare the robustness of the model and the baseline. To do so, we add Gaussian noise to the test data and check the accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d4719fdd-c6e1-4206-a2dd-cad3acae2a92",
   "metadata": {},
   "outputs": [],
   "source": [
    "stddev = 1e-1\n",
    "noise = tf.random.normal(tf.shape(x_test)) * stddev\n",
    "x_test_noised = x_test + noise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8736769-691c-4d38-8d3b-a127b31664b7",
   "metadata": {},
   "source": [
    "Or, non-Gaussian \"pixal-flipping\" noise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2fbd2684-e1d2-4c72-bef5-b436ebc2b35f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# flip_ratio = 0.01\n",
    "# x_test_noised = tf.where(tf.random.uniform(tf.shape(x_test)) < flip_ratio, 1 - x_test, x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "41d56ef7-827f-433a-aa72-c939d5beffbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_robustness(model):\n",
    "    accuracy = accuracy_score(\n",
    "        tf.argmax(y_test, axis=1), tf.argmax(model(x_test), axis=1))\n",
    "    accuracy_noised = accuracy_score(\n",
    "        tf.argmax(y_test, axis=1), tf.argmax(model(x_test_noised), axis=1))\n",
    "    print(f'Accuracy: {accuracy} -> {accuracy_noised}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "20a92992-0d08-4255-9098-9f091690e48c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8996 -> 0.8681\n"
     ]
    }
   ],
   "source": [
    "evaluate_robustness(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e8d06e85-1c3a-4641-a73f-bf8a5c7383de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9097 -> 0.7995\n"
     ]
    }
   ],
   "source": [
    "evaluate_robustness(baseline_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49ce4da5-feaf-42ea-a25a-cbf25b5fd89d",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "- By simply using the \"gradient loss\", we obtained a result that approaches the baseline. But the robustness is greatly out-performs the baseline.\n",
    "- Because the \"gradient loss\" computes gradients twice (once by x and y, and once by model variables), the training duration is doubled.\n",
    "- We also tested non-Gaussian noise, such as flipping the given ratio of pixals. The result is that the baseline model turns to be more robust than the model trained by the \"gradient loss\". The difference is that the pixal-flipping noise is not continuous. The noised images jump to other local minima of the loss function.\n",
    "- We also use MSE as loss to train the baseline model. The final performance is a little worse than the categorical cross-entropy, as expected. The above conclusion is invariant."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": ".venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

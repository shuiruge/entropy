{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "07274ccd-76f1-46a0-b64d-29dd3d7b8019",
   "metadata": {},
   "source": [
    "## Motivation\n",
    "\n",
    "In this notebook, we exame the idea declared in section 1.5.5 on Fashion MNIST data, a classification task.\n",
    "\n",
    "The model follows: https://www.kaggle.com/code/m0hand/fashion-mnist-cnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b8ab63f7-841b-4fe7-ae73-b0f8a207430e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-20 09:32:11.572486: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE3 SSE4.1 SSE4.2 AVX AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "from keras.models import Sequential\n",
    "from keras.losses import MSE, CategoricalCrossentropy\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tqdm import tqdm\n",
    "\n",
    "from utils import get_gradient_loss_fn\n",
    "\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c8239d4-600f-4b3d-b665-ba64d9bac711",
   "metadata": {},
   "source": [
    "## The MNIST Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d7ff4901-8ca8-4413-80ed-9184138a1ffa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([60000, 28, 28]), TensorShape([60000, 10]))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist = tf.keras.datasets.fashion_mnist\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "x_train = tf.convert_to_tensor(x_train / 255.0, 'float32')\n",
    "x_test = tf.convert_to_tensor(x_test / 255.0, 'float32')\n",
    "y_train = tf.one_hot(y_train, 10, dtype='float32')\n",
    "y_test = tf.one_hot(y_test, 10, dtype='float32')\n",
    "\n",
    "x_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "405d08b9-61df-44d1-a10f-9b2297783c3b",
   "metadata": {},
   "source": [
    "## Train a Model with Gradient Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "65e2d654-323d-43d2-805e-3a10fa1c28d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([ \n",
    "    Conv2D(64, (3, 3), activation='relu', input_shape=(28,28,1)),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    \n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "\n",
    "    Flatten(),\n",
    "    Dense(64, 'relu'),\n",
    "    Dense(10, 'softmax')\n",
    "])\n",
    "\n",
    "gradient_loss_fn = get_gradient_loss_fn(\n",
    "    lambda inputs: MSE(inputs[1], model(inputs[0]))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ac0e9b1c-d29b-4ef7-8ede-d29b98e069d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.optimizers.Adam()\n",
    "\n",
    "@tf.function\n",
    "def train_step(x, y):\n",
    "    with tf.GradientTape() as tape:\n",
    "        loss = gradient_loss_fn((x, y))\n",
    "    grads = tape.gradient(loss, model.variables)\n",
    "    optimizer.apply_gradients(zip(grads, model.variables))\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bd90d270-d554-4474-b95b-33c6826fee95",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model):\n",
    "    return accuracy_score(\n",
    "        tf.argmax(y_test, axis=1),\n",
    "        tf.argmax(model(x_test), axis=1),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1992d379-bf40-4022-bcd6-6d26c2b757f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
    "ds = ds.batch(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7f8317b9-e6c9-4c30-b3c6-7036e6785d07",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████| 600/600 [00:58<00:00, 10.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 tf.Tensor(0.0008826909, shape=(), dtype=float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████| 600/600 [00:58<00:00, 10.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 tf.Tensor(0.00066508434, shape=(), dtype=float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████| 600/600 [00:57<00:00, 10.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 tf.Tensor(0.0005956925, shape=(), dtype=float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████| 600/600 [00:58<00:00, 10.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 tf.Tensor(0.000531269, shape=(), dtype=float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████| 600/600 [00:57<00:00, 10.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 tf.Tensor(0.00045660275, shape=(), dtype=float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████| 600/600 [00:57<00:00, 10.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 tf.Tensor(0.00045052278, shape=(), dtype=float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████| 600/600 [00:58<00:00, 10.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 tf.Tensor(0.0004704871, shape=(), dtype=float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████| 600/600 [00:58<00:00, 10.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7 tf.Tensor(0.00045560423, shape=(), dtype=float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████| 600/600 [00:58<00:00, 10.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 tf.Tensor(0.00042795483, shape=(), dtype=float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████| 600/600 [00:57<00:00, 10.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9 tf.Tensor(0.0004996294, shape=(), dtype=float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(10):\n",
    "    for x, y in tqdm(ds):\n",
    "        loss = train_step(x, y)\n",
    "    print(epoch, loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "55dde9a7-4018-4e64-b909-e069729f096c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-20 09:41:55.163094: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 1730560000 exceeds 10% of free system memory.\n",
      "2024-03-20 09:41:55.628086: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 1730560000 exceeds 10% of free system memory.\n",
      "2024-03-20 09:41:56.098282: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 1730560000 exceeds 10% of free system memory.\n",
      "2024-03-20 09:41:56.524981: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 432640000 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9033"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7218605-525e-445c-aa7a-0e44d3d39dc1",
   "metadata": {},
   "source": [
    "## Baseline Model with Usual Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b9993ada-54dd-4b1f-ab9e-3e3301695c99",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_model = Sequential([ \n",
    "    Conv2D(64, (3, 3), activation='relu', input_shape=(28,28,1)),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    \n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "\n",
    "    Flatten(),\n",
    "    Dense(64, 'relu'),\n",
    "    Dense(10, 'softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2dc98178-5940-4567-be22-6735de610d85",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_model.compile(\n",
    "    optimizer='adam',\n",
    "    loss=CategoricalCrossentropy(),\n",
    "    # loss=MSE,\n",
    "    metrics=['accuracy'],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9fe0e479-a012-4538-a6ca-132352299fc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1875/1875 [==============================] - 27s 14ms/step - loss: 0.4547 - accuracy: 0.8366 - val_loss: 0.3450 - val_accuracy: 0.8765\n",
      "Epoch 2/20\n",
      "1875/1875 [==============================] - 27s 14ms/step - loss: 0.3042 - accuracy: 0.8894 - val_loss: 0.3493 - val_accuracy: 0.8744\n",
      "Epoch 3/20\n",
      "1875/1875 [==============================] - 27s 14ms/step - loss: 0.2610 - accuracy: 0.9032 - val_loss: 0.2871 - val_accuracy: 0.8944\n",
      "Epoch 4/20\n",
      "1875/1875 [==============================] - 28s 15ms/step - loss: 0.2298 - accuracy: 0.9150 - val_loss: 0.2556 - val_accuracy: 0.9074\n",
      "Epoch 5/20\n",
      "1875/1875 [==============================] - 28s 15ms/step - loss: 0.2067 - accuracy: 0.9234 - val_loss: 0.2711 - val_accuracy: 0.9023\n",
      "Epoch 6/20\n",
      "1875/1875 [==============================] - 28s 15ms/step - loss: 0.1850 - accuracy: 0.9311 - val_loss: 0.2859 - val_accuracy: 0.8954\n",
      "Epoch 7/20\n",
      "1875/1875 [==============================] - 28s 15ms/step - loss: 0.1666 - accuracy: 0.9380 - val_loss: 0.2649 - val_accuracy: 0.9076\n",
      "Epoch 8/20\n",
      "1875/1875 [==============================] - 29s 15ms/step - loss: 0.1508 - accuracy: 0.9430 - val_loss: 0.2629 - val_accuracy: 0.9110\n",
      "Epoch 9/20\n",
      "1875/1875 [==============================] - 27s 14ms/step - loss: 0.1379 - accuracy: 0.9475 - val_loss: 0.2569 - val_accuracy: 0.9124\n",
      "Epoch 10/20\n",
      "1875/1875 [==============================] - 26s 14ms/step - loss: 0.1250 - accuracy: 0.9527 - val_loss: 0.2970 - val_accuracy: 0.9056\n",
      "Epoch 11/20\n",
      "1875/1875 [==============================] - 26s 14ms/step - loss: 0.1135 - accuracy: 0.9571 - val_loss: 0.2893 - val_accuracy: 0.9072\n",
      "Epoch 12/20\n",
      "1875/1875 [==============================] - 26s 14ms/step - loss: 0.1030 - accuracy: 0.9607 - val_loss: 0.3178 - val_accuracy: 0.9089\n",
      "Epoch 13/20\n",
      "1875/1875 [==============================] - 26s 14ms/step - loss: 0.0943 - accuracy: 0.9648 - val_loss: 0.3488 - val_accuracy: 0.9067\n",
      "Epoch 14/20\n",
      "1875/1875 [==============================] - 26s 14ms/step - loss: 0.0859 - accuracy: 0.9680 - val_loss: 0.3202 - val_accuracy: 0.9113\n",
      "Epoch 15/20\n",
      "1875/1875 [==============================] - 26s 14ms/step - loss: 0.0778 - accuracy: 0.9700 - val_loss: 0.3328 - val_accuracy: 0.9092\n",
      "Epoch 16/20\n",
      "1875/1875 [==============================] - 25s 14ms/step - loss: 0.0719 - accuracy: 0.9730 - val_loss: 0.3803 - val_accuracy: 0.9028\n",
      "Epoch 17/20\n",
      "1875/1875 [==============================] - 26s 14ms/step - loss: 0.0660 - accuracy: 0.9754 - val_loss: 0.3996 - val_accuracy: 0.9081\n",
      "Epoch 18/20\n",
      "1875/1875 [==============================] - 26s 14ms/step - loss: 0.0604 - accuracy: 0.9775 - val_loss: 0.4292 - val_accuracy: 0.9046\n",
      "Epoch 19/20\n",
      "1875/1875 [==============================] - 26s 14ms/step - loss: 0.0551 - accuracy: 0.9788 - val_loss: 0.4424 - val_accuracy: 0.9052\n",
      "Epoch 20/20\n",
      "1875/1875 [==============================] - 26s 14ms/step - loss: 0.0529 - accuracy: 0.9800 - val_loss: 0.4571 - val_accuracy: 0.9070\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7f919c2c4750>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline_model.fit(\n",
    "    x_train, y_train,\n",
    "    epochs=20,\n",
    "    validation_data=(x_test, y_test),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "637a961b-4f4b-4c9a-a5d3-b944c1ea01a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-20 09:50:47.587941: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 1730560000 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.907"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(baseline_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cff6385a-4ca4-45fb-bf99-9953641fec71",
   "metadata": {},
   "source": [
    "## Model Robustness\n",
    "\n",
    "Now, we compare the robustness of the model and the baseline. To do so, we add Gaussian noise to the test data and check the accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d4719fdd-c6e1-4206-a2dd-cad3acae2a92",
   "metadata": {},
   "outputs": [],
   "source": [
    "stddev = 1e-1\n",
    "noise = tf.random.normal(tf.shape(x_test)) * stddev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "41d56ef7-827f-433a-aa72-c939d5beffbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_robustness(model):\n",
    "    accuracy = accuracy_score(\n",
    "        tf.argmax(y_test, axis=1), tf.argmax(model(x_test), axis=1))\n",
    "    noised_accuracy = accuracy_score(\n",
    "        tf.argmax(y_test, axis=1), tf.argmax(model(x_test+noise), axis=1))\n",
    "    print(f'Accuracy: {accuracy} -> {noised_accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "20a92992-0d08-4255-9098-9f091690e48c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9033 -> 0.8619\n"
     ]
    }
   ],
   "source": [
    "evaluate_robustness(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e8d06e85-1c3a-4641-a73f-bf8a5c7383de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.907 -> 0.8154\n"
     ]
    }
   ],
   "source": [
    "evaluate_robustness(baseline_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49ce4da5-feaf-42ea-a25a-cbf25b5fd89d",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "By simply using the \"gradient loss\", we obtain a result that approaches the baseline. But the robustness is greatly out-performs the baseline. Because the \"gradient loss\" computes gradients twice (once by x and y, and once by model variables), the training duration is doubled."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": ".venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

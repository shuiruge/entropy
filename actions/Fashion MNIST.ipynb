{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "07274ccd-76f1-46a0-b64d-29dd3d7b8019",
   "metadata": {},
   "source": [
    "## Motivation\n",
    "\n",
    "In this notebook, we exame the idea declared in section 1.5.5 on Fashion MNIST data, a classification task.\n",
    "\n",
    "The model follows: https://www.kaggle.com/code/m0hand/fashion-mnist-cnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b8ab63f7-841b-4fe7-ae73-b0f8a207430e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-21 14:24:17.441426: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE3 SSE4.1 SSE4.2 AVX AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "from keras.models import Sequential\n",
    "from keras.losses import MSE, CategoricalCrossentropy\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tqdm import tqdm\n",
    "\n",
    "from utils import GradientRelativeEntropy\n",
    "\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c8239d4-600f-4b3d-b665-ba64d9bac711",
   "metadata": {},
   "source": [
    "## The MNIST Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d7ff4901-8ca8-4413-80ed-9184138a1ffa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([60000, 28, 28]), TensorShape([60000, 10]))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist = tf.keras.datasets.fashion_mnist\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "x_train = tf.convert_to_tensor(x_train / 255.0, 'float32')\n",
    "x_test = tf.convert_to_tensor(x_test / 255.0, 'float32')\n",
    "y_train = tf.one_hot(y_train, 10, dtype='float32')\n",
    "y_test = tf.one_hot(y_test, 10, dtype='float32')\n",
    "\n",
    "x_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "405d08b9-61df-44d1-a10f-9b2297783c3b",
   "metadata": {},
   "source": [
    "## Train a Model with Gradient Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "65e2d654-323d-43d2-805e-3a10fa1c28d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([ \n",
    "    Conv2D(64, (3, 3), activation='relu', input_shape=(28,28,1)),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    \n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "\n",
    "    Flatten(),\n",
    "    Dense(64, 'relu'),\n",
    "    Dense(10, 'softmax')\n",
    "])\n",
    "\n",
    "gradient_loss_fn = GradientRelativeEntropy(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ac0e9b1c-d29b-4ef7-8ede-d29b98e069d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.optimizers.Adam()\n",
    "\n",
    "@tf.function\n",
    "def train_step(x, y):\n",
    "    with tf.GradientTape() as tape:\n",
    "        loss = gradient_loss_fn(x, y)\n",
    "    grads = tape.gradient(loss, model.variables)\n",
    "    optimizer.apply_gradients(zip(grads, model.variables))\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bd90d270-d554-4474-b95b-33c6826fee95",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model):\n",
    "    return accuracy_score(\n",
    "        tf.argmax(y_test, axis=1),\n",
    "        tf.argmax(model(x_test), axis=1),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1992d379-bf40-4022-bcd6-6d26c2b757f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
    "ds = ds.batch(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7f8317b9-e6c9-4c30-b3c6-7036e6785d07",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████| 600/600 [00:56<00:00, 10.69it/s]\n",
      "2024-03-21 14:25:35.518449: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 1730560000 exceeds 10% of free system memory.\n",
      "2024-03-21 14:25:35.963048: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 1730560000 exceeds 10% of free system memory.\n",
      "2024-03-21 14:25:36.478747: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 1730560000 exceeds 10% of free system memory.\n",
      "2024-03-21 14:25:36.912818: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 432640000 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.017590532 0.8261\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████| 600/600 [00:54<00:00, 10.96it/s]\n",
      "2024-03-21 14:26:32.421456: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 1730560000 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 0.016829625 0.8502\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████| 600/600 [01:05<00:00,  9.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 0.017404225 0.8497\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████| 600/600 [01:06<00:00,  9.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 0.01662075 0.8648\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████| 600/600 [01:06<00:00,  9.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 0.016316539 0.8704\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████| 600/600 [01:06<00:00,  8.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 0.016391957 0.8705\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████| 600/600 [01:07<00:00,  8.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 0.01598248 0.8833\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████| 600/600 [01:06<00:00,  9.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7 0.01573523 0.8851\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████| 600/600 [01:06<00:00,  9.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 0.015754428 0.8863\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████| 600/600 [01:06<00:00,  9.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9 0.016180752 0.8885\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████| 600/600 [01:05<00:00,  9.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 0.015613159 0.89\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████| 600/600 [01:05<00:00,  9.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11 0.015405157 0.8936\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████| 600/600 [01:03<00:00,  9.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12 0.015536223 0.8959\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████| 600/600 [00:55<00:00, 10.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13 0.015510559 0.898\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████| 600/600 [00:58<00:00, 10.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14 0.015406152 0.8967\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████| 600/600 [00:58<00:00, 10.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15 0.015751446 0.8956\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████| 600/600 [00:57<00:00, 10.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16 0.015495152 0.8982\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████| 600/600 [00:57<00:00, 10.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17 0.015629498 0.8945\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████| 600/600 [01:03<00:00,  9.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18 0.015373444 0.8951\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████| 600/600 [01:06<00:00,  9.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19 0.015497571 0.8955\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(20):\n",
    "    for x, y in tqdm(ds):\n",
    "        loss = train_step(x, y)\n",
    "    print(epoch, loss.numpy(), evaluate(model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "55dde9a7-4018-4e64-b909-e069729f096c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8955"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7218605-525e-445c-aa7a-0e44d3d39dc1",
   "metadata": {},
   "source": [
    "## Baseline Model with Usual Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b9993ada-54dd-4b1f-ab9e-3e3301695c99",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_model = Sequential([ \n",
    "    Conv2D(64, (3, 3), activation='relu', input_shape=(28,28,1)),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    \n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "\n",
    "    Flatten(),\n",
    "    Dense(64, 'relu'),\n",
    "    Dense(10, 'softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2dc98178-5940-4567-be22-6735de610d85",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_model.compile(\n",
    "    optimizer='adam',\n",
    "    loss=CategoricalCrossentropy(),\n",
    "    # loss=MSE,\n",
    "    metrics=['accuracy'],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9fe0e479-a012-4538-a6ca-132352299fc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1875/1875 - 31s - loss: 0.4600 - accuracy: 0.8345 - val_loss: 0.3484 - val_accuracy: 0.8784 - 31s/epoch - 16ms/step\n",
      "Epoch 2/20\n",
      "1875/1875 - 30s - loss: 0.3084 - accuracy: 0.8881 - val_loss: 0.3678 - val_accuracy: 0.8674 - 30s/epoch - 16ms/step\n",
      "Epoch 3/20\n",
      "1875/1875 - 30s - loss: 0.2665 - accuracy: 0.9017 - val_loss: 0.2989 - val_accuracy: 0.8884 - 30s/epoch - 16ms/step\n",
      "Epoch 4/20\n",
      "1875/1875 - 30s - loss: 0.2348 - accuracy: 0.9133 - val_loss: 0.2749 - val_accuracy: 0.9027 - 30s/epoch - 16ms/step\n",
      "Epoch 5/20\n",
      "1875/1875 - 30s - loss: 0.2103 - accuracy: 0.9231 - val_loss: 0.2737 - val_accuracy: 0.9015 - 30s/epoch - 16ms/step\n",
      "Epoch 6/20\n",
      "1875/1875 - 31s - loss: 0.1895 - accuracy: 0.9297 - val_loss: 0.2913 - val_accuracy: 0.8947 - 31s/epoch - 16ms/step\n",
      "Epoch 7/20\n",
      "1875/1875 - 29s - loss: 0.1712 - accuracy: 0.9357 - val_loss: 0.2658 - val_accuracy: 0.9053 - 29s/epoch - 15ms/step\n",
      "Epoch 8/20\n",
      "1875/1875 - 29s - loss: 0.1531 - accuracy: 0.9440 - val_loss: 0.2741 - val_accuracy: 0.9083 - 29s/epoch - 15ms/step\n",
      "Epoch 9/20\n",
      "1875/1875 - 29s - loss: 0.1405 - accuracy: 0.9469 - val_loss: 0.2625 - val_accuracy: 0.9112 - 29s/epoch - 15ms/step\n",
      "Epoch 10/20\n",
      "1875/1875 - 27s - loss: 0.1291 - accuracy: 0.9510 - val_loss: 0.2805 - val_accuracy: 0.9088 - 27s/epoch - 14ms/step\n",
      "Epoch 11/20\n",
      "1875/1875 - 27s - loss: 0.1166 - accuracy: 0.9554 - val_loss: 0.2930 - val_accuracy: 0.9081 - 27s/epoch - 14ms/step\n",
      "Epoch 12/20\n",
      "1875/1875 - 27s - loss: 0.1054 - accuracy: 0.9604 - val_loss: 0.3027 - val_accuracy: 0.9089 - 27s/epoch - 15ms/step\n",
      "Epoch 13/20\n",
      "1875/1875 - 28s - loss: 0.0945 - accuracy: 0.9636 - val_loss: 0.3363 - val_accuracy: 0.9076 - 28s/epoch - 15ms/step\n",
      "Epoch 14/20\n",
      "1875/1875 - 28s - loss: 0.0880 - accuracy: 0.9668 - val_loss: 0.3402 - val_accuracy: 0.9080 - 28s/epoch - 15ms/step\n",
      "Epoch 15/20\n",
      "1875/1875 - 28s - loss: 0.0787 - accuracy: 0.9705 - val_loss: 0.3457 - val_accuracy: 0.9064 - 28s/epoch - 15ms/step\n",
      "Epoch 16/20\n",
      "1875/1875 - 28s - loss: 0.0742 - accuracy: 0.9722 - val_loss: 0.3822 - val_accuracy: 0.9087 - 28s/epoch - 15ms/step\n",
      "Epoch 17/20\n",
      "1875/1875 - 28s - loss: 0.0684 - accuracy: 0.9738 - val_loss: 0.3967 - val_accuracy: 0.9070 - 28s/epoch - 15ms/step\n",
      "Epoch 18/20\n",
      "1875/1875 - 27s - loss: 0.0625 - accuracy: 0.9762 - val_loss: 0.3963 - val_accuracy: 0.9096 - 27s/epoch - 14ms/step\n",
      "Epoch 19/20\n",
      "1875/1875 - 28s - loss: 0.0585 - accuracy: 0.9777 - val_loss: 0.4208 - val_accuracy: 0.9097 - 28s/epoch - 15ms/step\n",
      "Epoch 20/20\n",
      "1875/1875 - 28s - loss: 0.0538 - accuracy: 0.9799 - val_loss: 0.4159 - val_accuracy: 0.9052 - 28s/epoch - 15ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7f9a17537710>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline_model.fit(\n",
    "    x_train, y_train,\n",
    "    epochs=20,\n",
    "    validation_data=(x_test, y_test),\n",
    "    verbose=2,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "637a961b-4f4b-4c9a-a5d3-b944c1ea01a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9052"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(baseline_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cff6385a-4ca4-45fb-bf99-9953641fec71",
   "metadata": {},
   "source": [
    "## Model Robustness\n",
    "\n",
    "Now, we compare the robustness of the model and the baseline. To do so, we add Gaussian noise to the test data and check the accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d4719fdd-c6e1-4206-a2dd-cad3acae2a92",
   "metadata": {},
   "outputs": [],
   "source": [
    "stddev = 1e-1\n",
    "noise = tf.random.normal(tf.shape(x_test)) * stddev\n",
    "x_test_noised = x_test + noise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8736769-691c-4d38-8d3b-a127b31664b7",
   "metadata": {},
   "source": [
    "Or, non-Gaussian \"pixal-flipping\" noise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "2fbd2684-e1d2-4c72-bef5-b436ebc2b35f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# flip_ratio = 0.02\n",
    "# x_test_noised = tf.where(tf.random.uniform(tf.shape(x_test)) < flip_ratio, 1 - x_test, x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "41d56ef7-827f-433a-aa72-c939d5beffbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_robustness(model):\n",
    "    accuracy = accuracy_score(\n",
    "        tf.argmax(y_test, axis=1), tf.argmax(model(x_test), axis=1))\n",
    "    accuracy_noised = accuracy_score(\n",
    "        tf.argmax(y_test, axis=1), tf.argmax(model(x_test_noised), axis=1))\n",
    "    print(f'Accuracy: {accuracy} -> {accuracy_noised}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "20a92992-0d08-4255-9098-9f091690e48c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8955 -> 0.8693\n"
     ]
    }
   ],
   "source": [
    "evaluate_robustness(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "e8d06e85-1c3a-4641-a73f-bf8a5c7383de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9052 -> 0.8136\n"
     ]
    }
   ],
   "source": [
    "evaluate_robustness(baseline_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49ce4da5-feaf-42ea-a25a-cbf25b5fd89d",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "- By simply using the \"gradient loss\", we obtained a result that approaches the baseline. But the robustness is greatly out-performs the baseline.\n",
    "- Because the \"gradient loss\" computes gradients twice (once by x and y, and once by model variables), the training duration is doubled.\n",
    "- We also tested non-Gaussian noise, such as flipping the given ratio of pixals. The result is that the model trained by the \"gradient loss\" is no more robust, but no less, than the baseline model. The difference is that the pixal-flipping noise is not continuous. The noised images jump to other local minima of the loss function.\n",
    "- We also use MSE as loss to train the baseline model. The final performance is a little worse than the categorical cross-entropy, as expected. The above conclusion is invariant."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": ".venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
